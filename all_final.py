import pandas as pdimport matplotlib.pyplot as pltimport seaborn as snsfrom sklearn.linear_model import LinearRegressionimport numpy as npfrom sklearn.model_selection import train_test_splitdf = pd.DataFrame()# Read all files and create a unique data frame containing all info, for train setfor i in range(1,15+1):    file = 'train/data_0{}.csv'.format(i)    df_new = pd.read_csv(file)    df = df.append(df_new,ignore_index=True)# Read file for test setfile = 'test/test_data_123.csv'df_test = pd.read_csv(file) # Set index as date so we don't have to deal with itdf = df.set_index('date')df_test = df_test.set_index('date')# # Remove all nan values# df.dropna(inplace = True)# df_test.dropna(inplace = True)# # Replace with mean# for col in df.columns:#     if df[col].dtype == 'float':#         df[col].fillna(df[col].mean(), inplace = True)# for col in df_test.columns:#     if df_test[col].dtype == 'float':#         df_test[col].fillna(df_test[col].mean(), inplace = True)# Handling missing values with zerodf.fillna(0, inplace = True)df_test.fillna(0, inplace = True)# See correlation to data pointsdicti = {'date': 0, 'T_AMB': 0, 'P_AMB': 0, 'CMP_SPEED': 1, 'CDP': 1, 'GGDP': 1, \          'HPT_IT': 1, 'CDT': 1, 'LPT_IT': 1, 'EXH_T': 1, 'RH': 0, 'WAR': 0, 'POWER': 1}# Selection of features and target for correlationfeatures = dftarget = df['POWER']# Calculation of abs correlation between POWER and all other varcorr_target = abs(features.corrwith(target)).to_frame().reset_index()corr_target = corr_target.rename(columns= {'index': 'var', 0:'corr'})# Add col with relation to turbine or ambientcorr_target['rel'] = corr_target['var'].map(dicti)# # Plot correlation# sns.barplot(y = 'var', x = 'corr', data = corr_target, hue = 'rel', orient = 'h', palette = 'Paired')# plt.title('Correlation to target (0: amb, 1: turbine)')# plt.xlabel('Correlation'); plt.ylabel('Variable')# plt.show()# Relation to turbine or ambientvar = pd.DataFrame(df.columns)# Map valuesvar['rel'] = var[0].map(dicti)# Extract only var with turbinevar = var[var['rel'] == 1]# Omit power of coursevar = var[:-1]high_corr = list(var[0])high_corr.remove('CDT')""""All train set"""# Split feature and target variablex = df[high_corr]y = df['POWER']# Initialize a Linear Reggression modellinreg = LinearRegression()# Fit (train) linreg to the train setlinreg.fit(x, y) # Predictions using the test setdf_test = df_test[high_corr]y_pred = linreg.predict(df_test)y_pred = pd.DataFrame(y_pred)# Let's add datesy_pred['date'] = df_new.datey_pred.columns =  ['POWER', 'date'] # rename cols namesy_pred = y_pred[['date','POWER']] # order correctly# y_pred.to_csv('Prueba1.csv', index = False)# Coeffinter = linreg.intercept_coef = linreg.coef_# Plot results (predictions over the year)sns.relplot(x="date", y="POWER",data = y_pred, kind="line")plt.title('Predictions power output of LPT (01-01-2021 - 01-01-2022)')plt.xlabel('Date'); plt.ylabel('Power (kW)')x1  = np.arange(1,396,33)labels = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']plt.xticks(x1, labels, rotation ='vertical')plt.show()""" Let's see how occurate our model is splitting our train set """# Initialize a Linear Reggression modellinreg = LinearRegression()# Split intro train and test set (the train set bc we have power)x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33)# Fit (train) linreg to the train setlinreg.fit(x_train, y_train) # Do predictionsy_pred2 = linreg.predict(x_test)# Visualize our resultsplt.scatter(x = y_test, y = y_pred2, s = 5, label = 'data', alpha = 0.5)plt.title('Predicted vs. actual power output')plt.xlabel('True values (kW)'); plt.ylabel('Predicted (kW)')# x = y relation should be, so s = 1i=min(y_test); s = 1x=np.linspace(i,max(y_test))plt.plot(x, s*x + i, color = 'black', label = 'slope = 1')plt.legend()plt.show()"""Evaluate"""from sklearn.metrics import r2_score, mean_squared_errorr2score = r2_score(y_test, y_pred2)mse = mean_squared_error(y_test, y_pred2)